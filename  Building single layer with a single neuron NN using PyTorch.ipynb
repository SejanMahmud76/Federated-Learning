{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6b4f11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b567a1-d718-4449-8810-634841d3e391",
   "metadata": {},
   "source": [
    "# Take input image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9bd2677-b08a-476c-8495-d1efd42e7bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = torch.randn(1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "878ad308-075e-4062-a40d-37f83ed9a5cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1358, -0.8318,  2.5724, -1.0813, -0.5210,  0.8518, -0.7374,  0.6213,\n",
       "         -0.4663, -0.0081]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36cb9a1-7872-4f36-9097-ed11a0e09a51",
   "metadata": {},
   "source": [
    "# Take input for weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ec20fb0-dc52-484f-9e3c-dac9610faddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.randn_like(input_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c4ece96-6e93-48a1-92a4-37ea08f68842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5158,  1.3911, -0.3548, -0.5660, -0.3440, -0.3964,  0.3392, -0.0741,\n",
       "         -1.6045,  1.3485]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d786cf-9df5-4bb6-ae6e-f0b0ba88a41a",
   "metadata": {},
   "source": [
    "# Take input for bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "722c2fd8-3e9d-444a-b166-ae49c279ce01",
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = torch.randn(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac66bee7-12bf-4181-8b97-85843edf207d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4085]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a409b195-a3b6-479f-ac56-8470e7df906b",
   "metadata": {},
   "source": [
    "#input_img*weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5142a72-8d4b-4efe-bd46-eeba89af9afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum of  input_img*weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af59bcb1-d4eb-4886-a82e-6f01a6c655f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3773d22-de67-4d66-8436-7141e2072702",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "528d19d5-d8ed-4d5b-adc0-b8c3fdee5d02",
   "metadata": {},
   "source": [
    "# Calculating Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35452001-fcc6-4cce-99c3-a1d2562b4f8e",
   "metadata": {},
   "source": [
    " input_img*weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0f581e7-17cb-4395-ba2a-0d3e045ff2f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0701, -1.1571, -0.9127,  0.6120,  0.1792, -0.3377, -0.2501, -0.0460,\n",
       "          0.7482, -0.0109]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " input_img*weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cb1c7c-1bb5-4889-830b-51979aef5d7f",
   "metadata": {},
   "source": [
    "sum of  input_img*weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd1b426b-34c0-46f7-a3f6-53eefca01b8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-1.2452)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum( input_img*weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6474f4a8-097d-4ee0-8773-dab8ff27c0f6",
   "metadata": {},
   "source": [
    " input_img*weights +weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b2bcd96-60ca-4ced-b72f-6cfebb795ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "output =  torch.sum(input_img*weights)+bias "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5c7f3e8-9990-4d2f-8737-0f460caab715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8368]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d00604a-a560-49a2-9be8-bc433d30b77a",
   "metadata": {},
   "source": [
    "# Use Activation Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3e8d9b-ea4b-4b44-af68-ef42425457c6",
   "metadata": {},
   "source": [
    "use sygmoid function to sclae the value of the output between 0 and 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff0d0a0-3794-46b7-8fcf-3d85b013c0b4",
   "metadata": {},
   "source": [
    "#Create Sygmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "58b54664-7bd5-4952-a552-9abb7f20f276",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+torch.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46468cd6-fea4-46bf-ac38-ac16207dcaff",
   "metadata": {},
   "source": [
    "#Pass the output to the function and store it to the output variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0d80a32-9efa-4c5d-9286-dbba41b466c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = sigmoid(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c2b78089-f603-4e40-9007-95cda92c3928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3022]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872d1a03-29f2-4968-be24-311794b36e65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
